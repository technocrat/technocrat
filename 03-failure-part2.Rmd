# The subprime mortgage crisis unfolds in early 2007, part 2

Keywords: logistic regression, confusion matrix

## The fall of FICO

The problem with the conventional wisdom of long standing is that it loses sight of history. The prominence of FICO in home loan credit underwriting described in the [Pinto Testimony] had its origins in a different time (the early 1990s) and a different lending environment. Freddie Mac was in a good position to ensure that all other things *were* equal. It made only what came to be called "prime" loans, generally for no more than 80% of the value of the property, under more stringent limitations on the debt-to-income ratio of the borrower and many other criteria that it kept within a narrow range, and offered only a few varieties of loans.

In the subprime market that emerged in the late 90s, all of those factors changed. Criteria that were narrow became broad, documentation was relaxed and a widespread assumption was that continually rising home values would preclude any problems. It's not surprising that FICO lost its predictive power.

## Overview of the *down* dependent variable

```{r setup4A, results="asis", echo = FALSE, warning=FALSE}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
library(tidyverse)
library(lubridate)
library(ggfortify)
library(DBI)
library(RMySQL)
library(knitr)
library(kableExtra)
library(texreg)
library(pander)
knitr::knit_hooks$set(inline = function(x) { if(!is.numeric(x)){ x }else{ prettyNum(round(x,2), big.mark=",") } })

drv <- dbDriver("MySQL")
con <- dbConnect(drv, username="root", password="", dbname ="dlf", host="localhost")
dn <- as.tibble(dbGetQuery(con, "SELECT deal, down from y7"))#
ggplot(dn, aes(x=down)) + geom_histogram(binwidth=1)
zerodown <- dn %>% filter(down < 0) %>% group_by(deal) %>% summarize("count" = n())
kable(zerodown, format.args = list(big.mark = ","), caption = "Number of loans with negative values of *down* by transaction")  %>% kable_styling(bootstrap_options = "striped", full_width = F) 
rm(dn, zerodown)
``` 

    MariaDB [dlf]> select down, count(down) from y7 group by down;
    +------+-------------+
    | down | count(down) |
    +------+-------------+
    |  -13 |           1 |
    |  -10 |           1 |
    |   -7 |           2 |
    |   -6 |           3 |
    |   -5 |           6 |
    |   -4 |           4 |
    |   -3 |          16 |
    |   -2 |          67 |
    |   -1 |         253 |
    |    0 |       64229 |
    |    1 |       10245 |
    |    2 |        4724 |
    |    3 |        2830 |
    |    4 |        2074 |
    |    5 |        1763 |
    |    6 |        1627 |
    |    7 |        1451 |
    |    8 |        1470 |
    |    9 |        1286 |
    |   10 |        1019 |
    |   11 |         852 |
    |   12 |         728 |
    |   13 |         600 |
    |   14 |         448 |
    |   15 |         306 |
    |   16 |         160 |
    |   17 |          88 |
    |   18 |          18 |
    +------+-------------+

Most of the loans are current -- *down* = 0 -- but a substantial number are in arrears by one or two payments or defaulted and in various stages of foreclosure.

The negative entries represent a few hundred loans that have made up to 13 months of advanced monthly payments (this was confirmed by checking a field in the database *ptd*, paid through date).

## Logistic Regression

### Restructuring the data

In this section we will be using logistic regression, for which we need a response variable that is binary, 1 or 0, performing or non-performing. This requires classifying the 28 values of *down.* I have chosen to classify two or fewer payments missed as performing (1), and three or more payments missed as non-performing (0). The binary performance variable will be named *perf.*

Some of the testing of FICO as a useful metric involved subsetting the data. There were many more variables than the ones used, some of them categorical and some categorical coded as numeric. Here is a summary of the remaining variables

```{r binarize, results="asis", echo = FALSE, warning=FALSE}
perf <- function(x) {ifelse (x <= 2, 1, 0)}
pcthit <- function(confusion_matrix) {((confusion_matrix[[1]] + confusion_matrix[,2][2])/sum(confusion_matrix))[[1]]}

y7pop <- as.tibble(dbGetQuery(con, "SELECT deal, down, fico, dti, cltv, obal, orate, fpd, +
grade, purpose, dtype, ltype, otype, ptype, zip, metro FROM y7"))
#training and testing sets must be created before application of perf function, which creates a matrix in y7pop, which breaks setdiff, which expects numeric in this situation
y7train <- y7pop %>% sample_frac(0.667, replace = TRUE)
y7test <- setdiff(y7train, y7pop) 
y7pop <- y7pop %>% filter(fico > 1) %>% mutate(fpd = as_date(fpd)) 
y7pop <- y7pop %>% mutate(perf = as.integer(perf(down)), down = NULL, fico = scale(fico))
y7pop<- y7pop %>% mutate(dti = scale(dti), cltv = scale(cltv))
y7pop <- y7pop %>% mutate(orate = scale(orate), obal = scale(obal))
# Summary
kable((y7pop %>% group_by(perf) %>% summarize(count = n())), format.args = list(big.mark = ","), caption = "Performance Summary")  %>% kable_styling(bootstrap_options = "striped", full_width = F)
kable((y7pop %>% group_by(grade) %>% summarize(count = n())), format.args = list(big.mark = ","), caption = "Origination Credit Grades Summary")  %>% kable_styling(bootstrap_options = "striped", full_width = F)
kable((y7pop %>% group_by(purpose) %>% summarize(count = n())), format.args = list(big.mark = ","), caption = "Loan Purpose Summary")  %>% kable_styling(bootstrap_options = "striped", full_width = F)
kable((y7pop %>% group_by(dtype) %>% summarize(count = n())), format.args = list(big.mark = ","), caption = "Underwriting Documentation Type")  %>% kable_styling(bootstrap_options = "striped", full_width = F)
kable((y7pop %>% group_by(ltype) %>% summarize(count = n())), format.args = list(big.mark = ","), caption = "Loan Type Summary")  %>% kable_styling(bootstrap_options = "striped", full_width = F)
kable((y7pop %>% group_by(otype) %>% summarize(count = n())), format.args = list(big.mark = ","), caption = "Occupancy Type Summary")  %>% kable_styling(bootstrap_options = "striped", full_width = F)
kable((y7pop %>% group_by(ptype) %>% summarize(count = n())), format.args = list(big.mark = ","), caption = "Property Type Summary")  %>% kable_styling(bootstrap_options = "striped", full_width = F)

rm(y7pop)
```


### Creating training and testing subsets and their subsamples

The next step is to split the original dataset into a training set of approximately 2/3 of the data and a test set of the data and normalize the numeric data to prepare for testing.

```{r, results="asis", echo = FALSE, warning=FALSE}
y7train <- y7train %>% filter(fico > 1) %>% mutate(fpd = as_date(fpd)) 
y7train <- y7train %>% mutate(perf = as.integer(perf(down)), down = NULL, fico = scale(fico))
y7train<- y7train %>% mutate(dti = scale(dti), cltv = scale(cltv))
y7train <- y7train %>% mutate(orate = scale(orate), obal = scale(obal))

y7test <- y7test %>% filter(fico > 1) %>% mutate(fpd = as_date(fpd)) 
y7test <- y7test %>% mutate(perf = as.integer(perf(down)), down = NULL, fico = scale(fico))
y7test<- y7test %>% mutate(dti = scale(dti), cltv = scale(cltv))
y7test <- y7test %>% mutate(orate = scale(orate), obal = scale(obal))
samtrain <- sample_frac(y7train, 0.12)
samtest <- sample_frac(y7test, 0.12)
```

This results in a training set with `r nrow(y7train)` and a test set with `r nrow(y7test)`, each of which is a moderately largish dataset in its own right, so we will sample 12% of each to get reduced sets, a training sample of `r nrow(samtrain)` and a test sample of `r nrow(samtest)`.

### Using the quantitative variables to predict loan performance with logistic regression

To start, we are going to return to the numeric variables, *fico, dti, cltv, obal and orate*. This time the dependent variable will not be continuous, as was *down* on the linear regression model, but binary, *perf*, with 1 for performing and 0 for non-performing. For this we use a generlized linear model on the sample of our training set.

```{r, results="asis", echo = FALSE, warning=FALSE}
pander(glm(perf~ fico + dti + cltv + obal + orate, data = samtrain, family = binomial))
```

All of the numeric variables have *some* degree of predictive power, except for *dti*.

Omitting *dti* yields

```{r, results="asis", echo = FALSE, warning=FALSE}
pander(glm(perf~ fico + cltv + obal + orate, data = samtrain, family = binomial),single.row = TRUE)
```

### Intepreting the results

#### How well does the training set self-classify?

```{r, results="asis", echo = FALSE, warning=FALSE}
quant.mod.train <- glm(perf~ fico + cltv + obal + orate, data = samtrain, family = binomial)
quant.mod.train.probs=predict(quant.mod.train,samtrain,type="response")
quant.mod.train.pred = rep("0", nrow(samtrain)) 
quant.mod.train.pred[quant.mod.train.probs > 0.5] = "1"
```

Given the training model, we are going to turn it on itself through the *predict* function, which will give the probability for each loan of its *perf* being non-zero. This produces what is called a *confusion matrix.*

```{r, results="asis", echo = FALSE, warning=FALSE}
pander(table(quant.mod.train.pred, samtrain$perf))
``` 

The model classified  `r round(pcthit(table(quant.mod.train.pred, samtrain$perf)),4)` of the outcomes as having a greater than 50% probability of performing (*i.e., better than guessing). If we had set the bar at 75%, the results are similar: `r round(sum(quant.mod.train.probs > 0.75)/nrow(samtrain),4)`. Reaching for 80% accuracy, however, drops the results to `r round(sum(quant.mod.train.probs > 0.80)/nrow(samtrain),4)`.

#### Does the training model do as well on the test sample it hasn't yet seen?

```{r, results="asis", echo = FALSE, warning=FALSE}
quant.mod.test.probs=predict(quant.mod.train,samtest,type="response")
quant.mod.test.pred = rep("0", nrow(samtest))         
quant.mod.test.pred[quant.mod.test.probs > 0.5] = "1"
pander(table(quant.mod.test.pred,samtest$perf))
```

The training model does quite well on the test data. The model classified `r round(pcthit(table(quant.mod.test.pred, samtest$perf)),4)` of the outcomes as having a greater than 50% probability of performing (*i.e., better than guessing). If we had set the bar at 75%, the results are similar: `r round(sum(quant.mod.test.probs > 0.75)/nrow(samtest),4)`. Reaching for 80% accuracy, however, drops the results to `r round(sum(quant.mod.test.probs > 0.80)/nrow(samtest),4)`.

### Next steps

We have a promising logistic model based on all of the quantitative variables but one, *dti*, that lacked predictive power. You could say, informally, that it has 75% accuracy. In the next installment, we will look at the effects of adding in the qualitative variables and move on to resampling and other cross validation methods.







[credit disclosure]: https://goo.gl/uhX1Pc
[LBMLT 2006-1]: https://www.sec.gov/Archives/edgar/data/1119605/000114420406002461/v033798_fwp.htm

[Pinto testimony]: https://democrats-oversight.house.gov/sites/democrats.oversight.house.gov/files/documents/Fannie%20Freddie%20Testimony%20of%20Edward%20Pinto%2012.9.08%20written%20submission%20Full.pdf


